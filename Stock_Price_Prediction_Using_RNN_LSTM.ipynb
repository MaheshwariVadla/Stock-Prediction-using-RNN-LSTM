{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock_Price_Prediction_Using_RNN_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlDliwRB4dCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0k8uGQfAZ8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "80fe8d13-8d1d-4aa8-c7ec-2fc0aa73f570"
      },
      "source": [
        "gs_train_df=pd.read_csv(\"Google_Stock_Price_Train.csv\")\n",
        "gs_train_df\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2012</td>\n",
              "      <td>325.25</td>\n",
              "      <td>332.83</td>\n",
              "      <td>324.97</td>\n",
              "      <td>663.59</td>\n",
              "      <td>7,380,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2012</td>\n",
              "      <td>331.27</td>\n",
              "      <td>333.87</td>\n",
              "      <td>329.08</td>\n",
              "      <td>666.45</td>\n",
              "      <td>5,749,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2012</td>\n",
              "      <td>329.83</td>\n",
              "      <td>330.75</td>\n",
              "      <td>326.89</td>\n",
              "      <td>657.21</td>\n",
              "      <td>6,590,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2012</td>\n",
              "      <td>328.34</td>\n",
              "      <td>328.77</td>\n",
              "      <td>323.68</td>\n",
              "      <td>648.24</td>\n",
              "      <td>5,405,900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2012</td>\n",
              "      <td>322.04</td>\n",
              "      <td>322.29</td>\n",
              "      <td>309.46</td>\n",
              "      <td>620.76</td>\n",
              "      <td>11,688,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>12/23/2016</td>\n",
              "      <td>790.90</td>\n",
              "      <td>792.74</td>\n",
              "      <td>787.28</td>\n",
              "      <td>789.91</td>\n",
              "      <td>623,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>12/27/2016</td>\n",
              "      <td>790.68</td>\n",
              "      <td>797.86</td>\n",
              "      <td>787.66</td>\n",
              "      <td>791.55</td>\n",
              "      <td>789,100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>12/28/2016</td>\n",
              "      <td>793.70</td>\n",
              "      <td>794.23</td>\n",
              "      <td>783.20</td>\n",
              "      <td>785.05</td>\n",
              "      <td>1,153,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>12/29/2016</td>\n",
              "      <td>783.33</td>\n",
              "      <td>785.93</td>\n",
              "      <td>778.92</td>\n",
              "      <td>782.79</td>\n",
              "      <td>744,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>12/30/2016</td>\n",
              "      <td>782.75</td>\n",
              "      <td>782.78</td>\n",
              "      <td>770.41</td>\n",
              "      <td>771.82</td>\n",
              "      <td>1,770,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1258 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date    Open    High     Low   Close      Volume\n",
              "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
              "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
              "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
              "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
              "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
              "...          ...     ...     ...     ...     ...         ...\n",
              "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
              "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
              "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
              "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
              "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
              "\n",
              "[1258 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2znfbsBaBPLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2cb537fc-199a-46e0-e910-8a980a045920"
      },
      "source": [
        "# here i have taken Date,open only \n",
        "gs_training_set = gs_train_df.iloc[:, 1:2].values\n",
        "gs_training_set"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[325.25],\n",
              "       [331.27],\n",
              "       [329.83],\n",
              "       ...,\n",
              "       [793.7 ],\n",
              "       [783.33],\n",
              "       [782.75]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyM2izEzBnZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "380e20fb-d316-4985-f55b-b8c6af6dae06"
      },
      "source": [
        "# feature scaling \n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "gs_training_set_scaleed = sc.fit_transform(gs_training_set)\n",
        "gs_training_set_scaleed"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08581368],\n",
              "       [0.09701243],\n",
              "       [0.09433366],\n",
              "       ...,\n",
              "       [0.95725128],\n",
              "       [0.93796041],\n",
              "       [0.93688146]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SwCBQfQCFsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a data structure with 60 timesteps and 1 output\n",
        "\n",
        "X_train = [] \n",
        "y_train = [] \n",
        "for i  in range(60,1258):\n",
        "    X_train.append(gs_training_set_scaleed[i-60:i,0])\n",
        "    y_train.append(gs_training_set_scaleed[i,0])\n",
        "X_train,y_train = np.array(X_train),np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZmnlYV9CySZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "7bc2e83b-1bcb-4ec5-857d-774b243c51eb"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08581368, 0.09701243, 0.09433366, ..., 0.07846566, 0.08034452,\n",
              "        0.08497656],\n",
              "       [0.09701243, 0.09433366, 0.09156187, ..., 0.08034452, 0.08497656,\n",
              "        0.08627874],\n",
              "       [0.09433366, 0.09156187, 0.07984225, ..., 0.08497656, 0.08627874,\n",
              "        0.08471612],\n",
              "       ...,\n",
              "       [0.92106928, 0.92438053, 0.93048218, ..., 0.95475854, 0.95204256,\n",
              "        0.95163331],\n",
              "       [0.92438053, 0.93048218, 0.9299055 , ..., 0.95204256, 0.95163331,\n",
              "        0.95725128],\n",
              "       [0.93048218, 0.9299055 , 0.93113327, ..., 0.95163331, 0.95725128,\n",
              "        0.93796041]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llk3rsqrC1Pg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "17a0ac1b-7559-4db7-ec44-0ce5972fdcae"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08627874, 0.08471612, 0.07454052, ..., 0.95725128, 0.93796041,\n",
              "       0.93688146])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDqJD6LsC5Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIRFdc0uC-ae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "2075c9c2-f54e-4a20-a993-afcf9cc990bf"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.08581368],\n",
              "        [0.09701243],\n",
              "        [0.09433366],\n",
              "        ...,\n",
              "        [0.07846566],\n",
              "        [0.08034452],\n",
              "        [0.08497656]],\n",
              "\n",
              "       [[0.09701243],\n",
              "        [0.09433366],\n",
              "        [0.09156187],\n",
              "        ...,\n",
              "        [0.08034452],\n",
              "        [0.08497656],\n",
              "        [0.08627874]],\n",
              "\n",
              "       [[0.09433366],\n",
              "        [0.09156187],\n",
              "        [0.07984225],\n",
              "        ...,\n",
              "        [0.08497656],\n",
              "        [0.08627874],\n",
              "        [0.08471612]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.92106928],\n",
              "        [0.92438053],\n",
              "        [0.93048218],\n",
              "        ...,\n",
              "        [0.95475854],\n",
              "        [0.95204256],\n",
              "        [0.95163331]],\n",
              "\n",
              "       [[0.92438053],\n",
              "        [0.93048218],\n",
              "        [0.9299055 ],\n",
              "        ...,\n",
              "        [0.95204256],\n",
              "        [0.95163331],\n",
              "        [0.95725128]],\n",
              "\n",
              "       [[0.93048218],\n",
              "        [0.9299055 ],\n",
              "        [0.93113327],\n",
              "        ...,\n",
              "        [0.95163331],\n",
              "        [0.95725128],\n",
              "        [0.93796041]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XbnNEk-DFv4",
        "colab_type": "text"
      },
      "source": [
        "**Building RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iyfzVhNDIup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "293b083d-71da-4ac1-efbb-8437ad07ce36"
      },
      "source": [
        "# importing the keras libraries  and packages\n",
        "!pip install tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZsrACJuEtza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "from tensorflow.python.keras.layers import LSTM\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZWYcnAEIv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initializing the RNN\n",
        "rnnclassifier = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RszW7C7eEWq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding the first LSTM layer and some Dropout regularisation\n",
        "\n",
        "rnnclassifier.add(LSTM(units = 50, return_sequences = True,input_shape = (X_train.shape[1],1)))\n",
        "rnnclassifier.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjRkYcVjGRK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "rnnclassifier.add(LSTM(units = 50, return_sequences = True))\n",
        "rnnclassifier.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvkiwrviGbj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "rnnclassifier.add(LSTM(units = 50, return_sequences = True))\n",
        "rnnclassifier.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3My7pHPiGiRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "rnnclassifier.add(LSTM(units = 50))\n",
        "rnnclassifier.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkz3sWkyGkw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the output layer\n",
        "rnnclassifier.add(Dense(units = 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0evM4ZSlG0Or",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c47d01e3-7147-4a1b-9ba3-194b2aeea3d4"
      },
      "source": [
        "# Compiling the RNN\n",
        "rnnclassifier.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "rnnclassifier.fit(X_train, y_train, epochs = 105, batch_size = 32)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/105\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0374\n",
            "Epoch 2/105\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0065\n",
            "Epoch 3/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0061\n",
            "Epoch 4/105\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0053\n",
            "Epoch 5/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0051\n",
            "Epoch 6/105\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0059\n",
            "Epoch 7/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0060\n",
            "Epoch 8/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0049\n",
            "Epoch 9/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0041\n",
            "Epoch 10/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0052\n",
            "Epoch 11/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0045\n",
            "Epoch 12/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0041\n",
            "Epoch 13/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0040\n",
            "Epoch 14/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0043\n",
            "Epoch 15/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0046\n",
            "Epoch 16/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0044\n",
            "Epoch 17/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0039\n",
            "Epoch 18/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0035\n",
            "Epoch 19/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0036\n",
            "Epoch 20/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0032\n",
            "Epoch 21/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0032\n",
            "Epoch 22/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0036\n",
            "Epoch 23/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0036\n",
            "Epoch 24/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0032\n",
            "Epoch 25/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0031\n",
            "Epoch 26/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0031\n",
            "Epoch 27/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0031\n",
            "Epoch 28/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0030\n",
            "Epoch 29/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0027\n",
            "Epoch 30/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0032\n",
            "Epoch 31/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0034\n",
            "Epoch 32/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0032\n",
            "Epoch 33/105\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.0027\n",
            "Epoch 34/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0030\n",
            "Epoch 35/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0033\n",
            "Epoch 36/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0026\n",
            "Epoch 37/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0026\n",
            "Epoch 38/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0024\n",
            "Epoch 39/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0026\n",
            "Epoch 40/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0027\n",
            "Epoch 41/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0028\n",
            "Epoch 42/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0031\n",
            "Epoch 43/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0023\n",
            "Epoch 44/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0025\n",
            "Epoch 45/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0025\n",
            "Epoch 46/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0023\n",
            "Epoch 47/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0022\n",
            "Epoch 48/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0023\n",
            "Epoch 49/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0023\n",
            "Epoch 50/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0023\n",
            "Epoch 51/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0021\n",
            "Epoch 52/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0024\n",
            "Epoch 53/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0023\n",
            "Epoch 54/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0024\n",
            "Epoch 55/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0022\n",
            "Epoch 56/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0020\n",
            "Epoch 57/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0020\n",
            "Epoch 58/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0022\n",
            "Epoch 59/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0020\n",
            "Epoch 60/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0021\n",
            "Epoch 61/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0019\n",
            "Epoch 62/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0020\n",
            "Epoch 63/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0019\n",
            "Epoch 64/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0023\n",
            "Epoch 65/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0020\n",
            "Epoch 66/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0019\n",
            "Epoch 67/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0020\n",
            "Epoch 68/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0020\n",
            "Epoch 69/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0020\n",
            "Epoch 70/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0019\n",
            "Epoch 71/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0017\n",
            "Epoch 72/105\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.0016\n",
            "Epoch 73/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0017\n",
            "Epoch 74/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0018\n",
            "Epoch 75/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0018\n",
            "Epoch 76/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0016\n",
            "Epoch 77/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0016\n",
            "Epoch 78/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0015\n",
            "Epoch 79/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0017\n",
            "Epoch 80/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0016\n",
            "Epoch 81/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0016\n",
            "Epoch 82/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0015\n",
            "Epoch 83/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0016\n",
            "Epoch 84/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0016\n",
            "Epoch 85/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0016\n",
            "Epoch 86/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0016\n",
            "Epoch 87/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0014\n",
            "Epoch 88/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0016\n",
            "Epoch 89/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0014\n",
            "Epoch 90/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0017\n",
            "Epoch 91/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0015\n",
            "Epoch 92/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0014\n",
            "Epoch 93/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0016\n",
            "Epoch 94/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0017\n",
            "Epoch 95/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0015\n",
            "Epoch 96/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0015\n",
            "Epoch 97/105\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.0014\n",
            "Epoch 98/105\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0014\n",
            "Epoch 99/105\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.0014\n",
            "Epoch 100/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0013\n",
            "Epoch 101/105\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0014\n",
            "Epoch 102/105\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0015\n",
            "Epoch 103/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0014\n",
            "Epoch 104/105\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0014\n",
            "Epoch 105/105\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f50069090b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gizaktRHG6bs",
        "colab_type": "text"
      },
      "source": [
        "**Making the predictions and visualising the predicted values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1xKFJOwHB8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the real stock price of 2017\n",
        "gs_test_df = pd.read_csv('Google_Stock_Price_Test.csv')\n",
        "real_stock_price = gs_test_df.iloc[:, 1:2].values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N60YpMGQHPHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the predicted stock price of 2017\n",
        "dataset_total = pd.concat((gs_train_df['Open'], gs_test_df['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(gs_test_df) - 60:].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdRzWlZMHzOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK4GQOoGH7xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "for i in range(60, 81):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = rnnclassifier.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLs5ckoQIETo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bc87399e-e069-43c7-ba2d-f8e9582b5bfe"
      },
      "source": [
        "# Visualising the results\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Google Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYIgtDDqT75L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}